{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5511e186",
   "metadata": {},
   "source": [
    "# Image classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f48eeff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71b40cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eeb60539",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=r\"C:\\Users\\harsh\\Downloads\\Fruits_Vegetables\\Fruits_Vegetables\\train\"\n",
    "test=r\"C:\\Users\\harsh\\Downloads\\Fruits_Vegetables\\Fruits_Vegetables\\test\"\n",
    "validation=r\"C:\\Users\\harsh\\Downloads\\Fruits_Vegetables\\Fruits_Vegetables\\validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e54fe00c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3115 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "data_train=tf.keras.utils.image_dataset_from_directory(train,\n",
    "                                                      validation_split=False,\n",
    "                                                      batch_size=32,\n",
    "                                                      shuffle=True,\n",
    "                                                      image_size=(180,180))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d2227c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_category=data_train.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f2e226c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['apple',\n",
       " 'banana',\n",
       " 'beetroot',\n",
       " 'bell pepper',\n",
       " 'cabbage',\n",
       " 'capsicum',\n",
       " 'carrot',\n",
       " 'cauliflower',\n",
       " 'chilli pepper',\n",
       " 'corn',\n",
       " 'cucumber',\n",
       " 'eggplant',\n",
       " 'garlic',\n",
       " 'ginger',\n",
       " 'grapes',\n",
       " 'jalepeno',\n",
       " 'kiwi',\n",
       " 'lemon',\n",
       " 'lettuce',\n",
       " 'mango',\n",
       " 'onion',\n",
       " 'orange',\n",
       " 'paprika',\n",
       " 'pear',\n",
       " 'peas',\n",
       " 'pineapple',\n",
       " 'pomegranate',\n",
       " 'potato',\n",
       " 'raddish',\n",
       " 'soy beans',\n",
       " 'spinach',\n",
       " 'sweetcorn',\n",
       " 'sweetpotato',\n",
       " 'tomato',\n",
       " 'turnip',\n",
       " 'watermelon']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3697e734",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 351 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "data_val=tf.keras.utils.image_dataset_from_directory(validation,\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=False,\n",
    "                                                    image_size=(180,180),\n",
    "                                                    validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72454704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 359 files belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "data_test=tf.keras.utils.image_dataset_from_directory(test,\n",
    "                                                    batch_size=32,\n",
    "                                                    shuffle=False,\n",
    "                                                    image_size=(180,180),\n",
    "                                                    validation_split=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5001ff5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TakeDataset element_spec=(TensorSpec(shape=(None, 180, 180, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6eb5cfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=tf.keras.Sequential([tf.keras.layers.Rescaling(1./255),\n",
    "                          tf.keras.layers.Conv2D(16,3,padding='same',activation='relu'),\n",
    "                          tf.keras.layers.MaxPooling2D(),\n",
    "                          tf.keras.layers.Conv2D(32,3,padding='same',activation='relu'),\n",
    "                          tf.keras.layers.MaxPooling2D(),\n",
    "                          tf.keras.layers.Conv2D(64,3,padding='same',activation='relu'),\n",
    "                          tf.keras.layers.MaxPooling2D(),\n",
    "                          tf.keras.layers.Flatten(),\n",
    "                          tf.keras.layers.Dropout(0.2),\n",
    "                          tf.keras.layers.Dense(128),\n",
    "                          tf.keras.layers.Dense(len(data_category))\n",
    "                          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e25dbbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "60745521",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/16\n",
      "98/98 [==============================] - 272s 3s/step - loss: 3.3925 - accuracy: 0.0918 - val_loss: 2.6281 - val_accuracy: 0.2764\n",
      "Epoch 2/16\n",
      "98/98 [==============================] - 222s 2s/step - loss: 2.5171 - accuracy: 0.2886 - val_loss: 1.6663 - val_accuracy: 0.5442\n",
      "Epoch 3/16\n",
      "98/98 [==============================] - 189s 2s/step - loss: 1.8967 - accuracy: 0.4578 - val_loss: 1.1749 - val_accuracy: 0.7066\n",
      "Epoch 4/16\n",
      "98/98 [==============================] - 185s 2s/step - loss: 1.2820 - accuracy: 0.6263 - val_loss: 0.5258 - val_accuracy: 0.8604\n",
      "Epoch 5/16\n",
      "98/98 [==============================] - 183s 2s/step - loss: 0.6763 - accuracy: 0.8125 - val_loss: 0.4528 - val_accuracy: 0.9060\n",
      "Epoch 6/16\n",
      "98/98 [==============================] - 187s 2s/step - loss: 0.3682 - accuracy: 0.9027 - val_loss: 0.4152 - val_accuracy: 0.9259\n",
      "Epoch 7/16\n",
      "98/98 [==============================] - 179s 2s/step - loss: 0.2433 - accuracy: 0.9387 - val_loss: 0.3424 - val_accuracy: 0.9345\n",
      "Epoch 8/16\n",
      "98/98 [==============================] - 189s 2s/step - loss: 0.1996 - accuracy: 0.9531 - val_loss: 0.3176 - val_accuracy: 0.9544\n",
      "Epoch 9/16\n",
      "98/98 [==============================] - 174s 2s/step - loss: 0.1524 - accuracy: 0.9660 - val_loss: 0.2917 - val_accuracy: 0.9573\n",
      "Epoch 10/16\n",
      "98/98 [==============================] - 187s 2s/step - loss: 0.1430 - accuracy: 0.9692 - val_loss: 0.3559 - val_accuracy: 0.9630\n",
      "Epoch 11/16\n",
      "98/98 [==============================] - 198s 2s/step - loss: 0.1276 - accuracy: 0.9753 - val_loss: 0.3748 - val_accuracy: 0.9630\n",
      "Epoch 12/16\n",
      "98/98 [==============================] - 172s 2s/step - loss: 0.1005 - accuracy: 0.9801 - val_loss: 0.3562 - val_accuracy: 0.9573\n",
      "Epoch 13/16\n",
      "98/98 [==============================] - 173s 2s/step - loss: 0.0834 - accuracy: 0.9846 - val_loss: 0.3669 - val_accuracy: 0.9658\n",
      "Epoch 14/16\n",
      "98/98 [==============================] - 190s 2s/step - loss: 0.0827 - accuracy: 0.9862 - val_loss: 0.3847 - val_accuracy: 0.9601\n",
      "Epoch 15/16\n",
      "98/98 [==============================] - 180s 2s/step - loss: 0.0712 - accuracy: 0.9872 - val_loss: 0.3600 - val_accuracy: 0.9601\n",
      "Epoch 16/16\n",
      "98/98 [==============================] - 178s 2s/step - loss: 0.0638 - accuracy: 0.9878 - val_loss: 0.3532 - val_accuracy: 0.9658\n"
     ]
    }
   ],
   "source": [
    "history=model.fit(data_train,validation_data=data_val,epochs=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4f84a3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "image=r\"C:\\Users\\harsh\\Downloads\\banana.jpg\"\n",
    "load_img=tf.keras.utils.load_img(image,target_size=(180,180))\n",
    "img_array=tf.keras.utils.array_to_img(load_img)\n",
    "img_batch=tf.expand_dims(img_array,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5294cac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    }
   ],
   "source": [
    "predict=model.predict(img_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c707dc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "score=tf.nn.softmax(predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f75f6a5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'banana'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_category[np.argmax(score)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a2e4c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the fruit/vegitable that our model has predicted is banana with the accuracy of 63.65%\n"
     ]
    }
   ],
   "source": [
    "print(f'the fruit/vegitable that our model has predicted is {data_category[np.argmax(score)]} with the accuracy of {round(np.max(score)*100,2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "29a90c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'C:\\Users\\harsh\\OneDrive\\Desktop\\Image_classifier_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e604a76f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1ce56d41",
   "metadata": {},
   "outputs": [],
   "source": [
    "icm=tf.keras.models.load_model('Image_classifier_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa559aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
